Trabalho 1 da cadeira de Coleta, Preparação e Análise de Dados (2024/02)
Integrantes: Bruno Fernandes, Vitor Esposito e Julia Peixoto

----------------------------------------------------

Para rodar esse trabalho serão necessários 2 ambientes conda:
  - ambiente 1:
	Python 2.7 ($ conda create --name {nome_env1} python=2.7)
 	Biblioteca Pillow ($ conda install pillow)

  - ambiente 2:
	Python 3.X ($ conda create --name {nome_env2} python)
	Bibliotecas Requests, BeautifulSoup e Selenium, Time e Json ($ conda install requests bs4 selenium)

----------------------------------------------------

Instruções de uso para a tarefa 1:
  - Executar o script web2py.py usando o ambiente {nome_env1}, ao fazer isso uma interface gráfica será
  aberta e vai permitir que você coloque uma senha e comece a usar a aplicação web. Se você
  estiver usando as opções padrão, o endereço no qual você vai acessar o site é http://127.0.0.1:8000/places/
  - Abrir o arquivo "tarefa1.ipynb" presente neste mesmo diretório
  - Rodar todas as células
  - Arquivos de saída estão presentes no diretório ./tarefa1
  - Testar como achar melhor :)

Instruções de uso para a tarefa 1:
  - Abrir o arquivo "tarefa2.ipynb" presente neste mesmo diretório
  - Rodar todas as células. Será necessário ter o Chrome Driver para executar a etapa "2.1 - Crawler" do notebook,
  se preferir, rodar somente os imports primários e as células presentes na etapa "2.2 - Scraping dos filmes"
  - Arquivos de saída estão presentes no diretório ./tarefa2
  - Testar como achar melhor :)